{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM IMDB Movie Review Tutorial\n",
    "Josiah Olson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Input, merge, BatchNormalization, GRU\n",
    "from keras.datasets import imdb\n",
    "\n",
    "import os\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "max_len = 200  # cut texts after this number of words (among top max_features most common words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get dataset and unzip: http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "path = 'C:/2_MyThesis/ThucNghiem/Data/VS_4D/out/train/pos/'\n",
    "X_train.extend([open(path + f).read() for f in os.listdir(path) if f.endswith('.txt')])\n",
    "y_train.extend([1 for _ in range(854)])\n",
    "\n",
    "path = 'C:/2_MyThesis/ThucNghiem/Data/VS_4D/out/train/neg/'\n",
    "X_train.extend([open(path + f).read() for f in os.listdir(path) if f.endswith('.txt')])\n",
    "y_train.extend([0 for _ in range(238)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "path = 'C:/2_MyThesis/ThucNghiem/Data/VS_4D/out/test/pos/'\n",
    "X_test.extend([open(path + f).read() for f in os.listdir(path) if f.endswith('.txt')])\n",
    "y_test.extend([1 for _ in range(375)])\n",
    "\n",
    "path = 'C:/2_MyThesis/ThucNghiem/Data/VS_4D/out/test/neg/'\n",
    "X_test.extend([open(path + f).read() for f in os.listdir(path) if f.endswith('.txt')])\n",
    "y_test.extend([0 for _ in range(88)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tokenize works to list of integers where each integer is a key to a word\n",
    "imdbTokenizer = Tokenizer(nb_words=max_features)\n",
    "\n",
    "imdbTokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 trong\n",
      "13 giá\n",
      "12 cho\n",
      "8 có\n",
      "1 và\n",
      "18 đã\n",
      "15 đầu\n",
      "4 đồng\n",
      "14 công\n",
      "7 các\n",
      "17 được\n",
      "3 của\n",
      "11 tăng\n",
      "5 năm\n",
      "10 tỷ\n",
      "16 doanh\n",
      "19 cổ\n",
      "6 với\n",
      "9 là\n"
     ]
    }
   ],
   "source": [
    "#print top 20 words \n",
    "#note zero is reserved for non frequent words\n",
    "for word, value in imdbTokenizer.word_index.items():\n",
    "    if value < 20:\n",
    "        print(value, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "và\n",
      "trong\n",
      "sản\n"
     ]
    }
   ],
   "source": [
    "#create int to word dictionary\n",
    "intToWord = {}\n",
    "for word, value in imdbTokenizer.word_index.items():\n",
    "    intToWord[value] = word\n",
    "\n",
    "#add a symbol for null placeholder\n",
    "intToWord[0] = \"!!!NA!!!\"\n",
    "    \n",
    "print(intToWord[1])\n",
    "print(intToWord[2])\n",
    "print(intToWord[32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " trong tổng_số mã cổ_phiếu giảm_giá trong năm mã giảm mạnh nhất với bao_gồm svn gtt hla ptk dc avf asa hly hsi và th nhóm ngành xây_dựng và bất_động_sản ngành xây_dựng ngày niêm_yết vốn điều_lệ đồng giá đã điều_chỉnh đầu năm nbsp đồng cpgiá tại ngày phiên cuối năm đồng cp tỷ_lệ giảm khối_lượng giao_dịch bình_quân tuần cpnhóm ngành vận_tải và kho_bãi ngành vận_chuyển khách đường_bộ hệ_thống trạm dừng ngày niêm_yết vốn điều_lệ đồnggiá đã điều_chỉnh đầu năm đồng cpgiá tại ngày phiên cuối năm đồng cptỷ lệ giảm khối_lượng giao_dịch bình_quân tuần cpnhóm ngành sản_xuất ngành kim_loại và các sản_phẩm từ khoáng phi kim_loại ngày niêm_yết vốn điều_lệ đồng giá đã điều_chỉnh đầu năm đồng cpgiá tại ngày phiên cuối năm đồng cp tỷ_lệ giảm khối_lượng giao_dịch bình_quân tuần cpnhóm ngành khai_khoáng ngành khai_khoáng khác ngày niêm_yết vốn điều_lệ đồnggiá đã điều_chỉnh đầu năm đồng cpgiá tại ngày phiên cuối năm đồng cptỷ lệ giảm khối_lượng giao_dịch bình_quân tuần cpnhóm ngành xây_dựng và bất_động_sản ngành xây_dựng ngày niêm_yết vốn điều_lệ đồng giá đã điều_chỉnh đầu năm đồng cpgiá tại ngày phiên cuối năm đồng cp tỷ_lệ giảm khối_lượng giao_dịch bình_quân tuần cpnhóm ngành sản_xuất ngành thực_phẩm đồ uống thuốc_lá ngày niêm_yết vốn điều_lệ đồng giá đã điều_chỉnh đầu năm đồng cpgiá tại ngày phiên cuối năm đồng cp tỷ_lệ giảm khối_lượng giao_dịch bình_quân tuần cpnhóm ngành sản_xuất ngành hóa_chất dược_phẩm ngày niêm_yết vốn điều_lệ đồnggiá đã điều_chỉnh đầu năm đồng cpgiá tại ngày phiên cuối năm đồng cp tỷ_lệ giảm khối_lượng giao_dịch bình_quân tuần cpnhóm ngành sản_xuất ngành kim_loại và các sản_phẩm từ khoáng phi kim_loại ngày niêm_yết vốn điều_lệ đồnggiá đã điều_chỉnh đầu năm đồng cpgiá tại ngày phiên cuối năm đồng cp tỷ_lệ giảm khối_lượng giao_dịch bình_quân tuần cpnhóm ngành sản_xuất ngành hóa_chất dược_phẩm ngày niêm_yết vốn điều_lệ đồng giá đã điều_chỉnh đầu năm đồng cpgiá tại ngày phiên cuối năm đồng cp tỷ_lệ giảm khối_lượng giao_dịch bình_quân tuần cpnhóm ngành thương_mại ngành bán_buôn ngày niêm_yết vốn điều_lệ đồnggiá đã điều_chỉnh đầu năm nbsp đồng cpgiá tại ngày phiên cuối năm đồng cp tỷ_lệ giảm khối_lượng giao_dịch bình_quân tuần cp nbsp nhóm ngành xây_dựng và bất_động_sản ngành xây_dựng ngày niêm_yết vốn điều_lệ đồng giá đã điều_chỉnh đầu năm nbsp đồng cpgiá tại ngày phiên cuối năm đồng cp tỷ_lệ giảm khối_lượng giao_dịch bình_quân tuần cpnhóm ngành vận_tải và kho_bãi ngành vận_chuyển khách đường_bộ hệ_thống trạm dừng ngày niêm_yết vốn điều_lệ đồnggiá đã điều_chỉnh đầu năm đồng cpgiá tại ngày phiên cuối năm đồng cptỷ lệ giảm khối_lượng giao_dịch bình_quân tuần cpnhóm ngành sản_xuất ngành kim_loại và các sản_phẩm từ khoáng phi kim_loại ngày niêm_yết vốn điều_lệ đồng giá đã điều_chỉnh đầu năm đồng cpgiá tại ngày phiên cuối năm đồng cp tỷ_lệ giảm khối_lượng giao_dịch bình_quân tuần cpnhóm ngành khai_khoáng ngành khai_khoáng khác ngày niêm_yết vốn điều_lệ đồnggiá đã điều_chỉnh đầu năm đồng cpgiá tại ngày phiên cuối năm đồng cptỷ lệ giảm khối_lượng giao_dịch bình_quân tuần cpnhóm ngành xây_dựng và bất_động_sản ngành xây_dựng ngày niêm_yết vốn điều_lệ đồng giá đã điều_chỉnh đầu năm đồng cpgiá tại ngày phiên cuối năm đồng cp tỷ_lệ giảm khối_lượng giao_dịch bình_quân tuần cpnhóm ngành sản_xuất ngành thực_phẩm đồ uống thuốc_lá ngày niêm_yết vốn điều_lệ đồng giá đã điều_chỉnh đầu năm đồng cpgiá tại ngày phiên cuối năm đồng cp tỷ_lệ giảm khối_lượng giao_dịch bình_quân tuần cpnhóm ngành sản_xuất ngành hóa_chất dược_phẩm ngày niêm_yết vốn điều_lệ đồnggiá đã điều_chỉnh đầu năm đồng cpgiá tại ngày phiên cuối năm đồng cp tỷ_lệ giảm khối_lượng giao_dịch bình_quân tuần cpnhóm ngành sản_xuất ngành kim_loại và các sản_phẩm từ khoáng phi kim_loại ngày niêm_yết vốn điều_lệ đồnggiá đã điều_chỉnh đầu năm đồng cpgiá tại ngày phiên cuối năm đồng cp tỷ_lệ giảm khối_lượng giao_dịch bình_quân tuần cpnhóm ngành sản_xuất ngành hóa_chất dược_phẩm ngày niêm_yết vốn điều_lệ đồng giá đã điều_chỉnh đầu năm đồng cpgiá tại ngày phiên cuối năm đồng cp tỷ_lệ giảm khối_lượng giao_dịch bình_quân tuần cpnhóm ngành thương_mại ngành bán_buôn ngày niêm_yết vốn điều_lệ đồnggiá đã điều_chỉnh đầu năm nbsp đồng cpgiá tại ngày phiên cuối năm đồng cp tỷ_lệ giảm khối_lượng giao_dịch bình_quân tuần cp nbsp \n",
      "[[2, 94, 39, 454, 19, 70, 25, 13, 2, 5, 454, 25, 75, 99, 6, 505, 437, 4722, 2979, 1345, 3517, 6770, 1812, 6780, 6822, 3508, 1, 2635, 212, 155, 211, 245, 1, 210, 27, 32, 155, 211, 245, 114, 388, 393, 55, 69, 171, 4, 13, 18, 69, 332, 15, 5, 80, 4, 1829, 35, 114, 126, 236, 5, 4, 274, 10, 171, 25, 285, 119, 74, 112, 208, 445, 289, 2000, 155, 427, 522, 1, 571, 1176, 155, 427, 198, 283, 187, 138, 360, 267, 1242, 963, 114, 388, 393, 55, 69, 171, 3091, 18, 69, 332, 15, 5, 4, 1829, 35, 114, 126, 236, 5, 4, 4031, 171, 25, 285, 119, 74, 112, 208, 445, 289, 2000, 155, 32, 76, 155, 641, 504, 1, 7, 32, 238, 26, 920, 916, 641, 504, 114, 388, 393, 55, 69, 171, 4, 13, 18, 69, 332, 15, 5, 4, 1829, 35, 114, 126, 236, 5, 4, 274, 10, 171, 25, 285, 119, 74, 112, 208, 445, 289, 2000, 155, 216, 920, 155, 216, 920, 188, 114, 388, 393, 55, 69, 171, 3091, 18, 69, 332, 15, 5, 4, 1829, 35, 114, 126, 236, 5, 4, 4031, 171, 25, 285, 119, 74, 112, 208, 445, 289, 2000, 155, 211, 245, 1, 210, 27, 32, 155, 211, 245, 114, 388, 393, 55, 69, 171, 4, 13, 18, 69, 332, 15, 5, 4, 1829, 35, 114, 126, 236, 5, 4, 274, 10, 171, 25, 285, 119, 74, 112, 208, 445, 289, 2000, 155, 32, 76, 155, 87, 238, 889, 1354, 1081, 2171, 114, 388, 393, 55, 69, 171, 4, 13, 18, 69, 332, 15, 5, 4, 1829, 35, 114, 126, 236, 5, 4, 274, 10, 171, 25, 285, 119, 74, 112, 208, 445, 289, 2000, 155, 32, 76, 155, 237, 453, 904, 238, 114, 388, 393, 55, 69, 171, 3091, 18, 69, 332, 15, 5, 4, 1829, 35, 114, 126, 236, 5, 4, 274, 10, 171, 25, 285, 119, 74, 112, 208, 445, 289, 2000, 155, 32, 76, 155, 641, 504, 1, 7, 32, 238, 26, 920, 916, 641, 504, 114, 388, 393, 55, 69, 171, 3091, 18, 69, 332, 15, 5, 4, 1829, 35, 114, 126, 236, 5, 4, 274, 10, 171, 25, 285, 119, 74, 112, 208, 445, 289, 2000, 155, 32, 76, 155, 237, 453, 904, 238, 114, 388, 393, 55, 69, 171, 4, 13, 18, 69, 332, 15, 5, 4, 1829, 35, 114, 126, 236, 5, 4, 274, 10, 171, 25, 285, 119, 74, 112, 208, 445, 289, 2000, 155, 202, 331, 155, 88, 1252, 114, 388, 393, 55, 69, 171, 3091, 18, 69, 332, 15, 5, 80, 4, 1829, 35, 114, 126, 236, 5, 4, 274, 10, 171, 25, 285, 119, 74, 112, 208, 445, 289, 274, 80, 212, 155, 211, 245, 1, 210, 27, 32, 155, 211, 245, 114, 388, 393, 55, 69, 171, 4, 13, 18, 69, 332, 15, 5, 80, 4, 1829, 35, 114, 126, 236, 5, 4, 274, 10, 171, 25, 285, 119, 74, 112, 208, 445, 289, 2000, 155, 427, 522, 1, 571, 1176, 155, 427, 198, 283, 187, 138, 360, 267, 1242, 963, 114, 388, 393, 55, 69, 171, 3091, 18, 69, 332, 15, 5, 4, 1829, 35, 114, 126, 236, 5, 4, 4031, 171, 25, 285, 119, 74, 112, 208, 445, 289, 2000, 155, 32, 76, 155, 641, 504, 1, 7, 32, 238, 26, 920, 916, 641, 504, 114, 388, 393, 55, 69, 171, 4, 13, 18, 69, 332, 15, 5, 4, 1829, 35, 114, 126, 236, 5, 4, 274, 10, 171, 25, 285, 119, 74, 112, 208, 445, 289, 2000, 155, 216, 920, 155, 216, 920, 188, 114, 388, 393, 55, 69, 171, 3091, 18, 69, 332, 15, 5, 4, 1829, 35, 114, 126, 236, 5, 4, 4031, 171, 25, 285, 119, 74, 112, 208, 445, 289, 2000, 155, 211, 245, 1, 210, 27, 32, 155, 211, 245, 114, 388, 393, 55, 69, 171, 4, 13, 18, 69, 332, 15, 5, 4, 1829, 35, 114, 126, 236, 5, 4, 274, 10, 171, 25, 285, 119, 74, 112, 208, 445, 289, 2000, 155, 32, 76, 155, 87, 238, 889, 1354, 1081, 2171, 114, 388, 393, 55, 69, 171, 4, 13, 18, 69, 332, 15, 5, 4, 1829, 35, 114, 126, 236, 5, 4, 274, 10, 171, 25, 285, 119, 74, 112, 208, 445, 289, 2000, 155, 32, 76, 155, 237, 453, 904, 238, 114, 388, 393, 55, 69, 171, 3091, 18, 69, 332, 15, 5, 4, 1829, 35, 114, 126, 236, 5, 4, 274, 10, 171, 25, 285, 119, 74, 112, 208, 445, 289, 2000, 155, 32, 76, 155, 641, 504, 1, 7, 32, 238, 26, 920, 916, 641, 504, 114, 388, 393, 55, 69, 171, 3091, 18, 69, 332, 15, 5, 4, 1829, 35, 114, 126, 236, 5, 4, 274, 10, 171, 25, 285, 119, 74, 112, 208, 445, 289, 2000, 155, 32, 76, 155, 237, 453, 904, 238, 114, 388, 393, 55, 69, 171, 4, 13, 18, 69, 332, 15, 5, 4, 1829, 35, 114, 126, 236, 5, 4, 274, 10, 171, 25, 285, 119, 74, 112, 208, 445, 289, 2000, 155, 202, 331, 155, 88, 1252, 114, 388, 393, 55, 69, 171, 3091, 18, 69, 332, 15, 5, 80, 4, 1829, 35, 114, 126, 236, 5, 4, 274, 10, 171, 25, 285, 119, 74, 112, 208, 445, 289, 274, 80]]\n",
      "trong\n",
      "tổng\n",
      "số\n",
      "mã\n",
      "cổ\n",
      "phiếu\n",
      "giảm\n",
      "giá\n",
      "trong\n",
      "năm\n",
      "mã\n",
      "giảm\n",
      "mạnh\n",
      "nhất\n",
      "với\n",
      "bao\n",
      "gồm\n",
      "svn\n",
      "gtt\n",
      "hla\n",
      "ptk\n",
      "dc\n",
      "avf\n",
      "asa\n",
      "hly\n",
      "hsi\n",
      "và\n",
      "th\n",
      "nhóm\n",
      "ngành\n",
      "xây\n",
      "dựng\n",
      "và\n",
      "bất\n",
      "động\n",
      "sản\n",
      "ngành\n",
      "xây\n",
      "dựng\n",
      "ngày\n",
      "niêm\n",
      "yết\n",
      "vốn\n",
      "điều\n",
      "lệ\n",
      "đồng\n",
      "giá\n",
      "đã\n",
      "điều\n",
      "chỉnh\n",
      "đầu\n",
      "năm\n",
      "nbsp\n",
      "đồng\n",
      "cpgiá\n",
      "tại\n",
      "ngày\n",
      "phiên\n",
      "cuối\n",
      "năm\n",
      "đồng\n",
      "cp\n",
      "tỷ\n",
      "lệ\n",
      "giảm\n",
      "khối\n",
      "lượng\n",
      "giao\n",
      "dịch\n",
      "bình\n",
      "quân\n",
      "tuần\n",
      "cpnhóm\n",
      "ngành\n",
      "vận\n",
      "tải\n",
      "và\n",
      "kho\n",
      "bãi\n",
      "ngành\n",
      "vận\n",
      "chuyển\n",
      "khách\n",
      "đường\n",
      "bộ\n",
      "hệ\n",
      "thống\n",
      "trạm\n",
      "dừng\n",
      "ngày\n",
      "niêm\n",
      "yết\n",
      "vốn\n",
      "điều\n",
      "lệ\n",
      "đồnggiá\n",
      "đã\n",
      "điều\n",
      "chỉnh\n",
      "đầu\n",
      "năm\n",
      "đồng\n",
      "cpgiá\n",
      "tại\n",
      "ngày\n",
      "phiên\n",
      "cuối\n",
      "năm\n",
      "đồng\n",
      "cptỷ\n",
      "lệ\n",
      "giảm\n",
      "khối\n",
      "lượng\n",
      "giao\n",
      "dịch\n",
      "bình\n",
      "quân\n",
      "tuần\n",
      "cpnhóm\n",
      "ngành\n",
      "sản\n",
      "xuất\n",
      "ngành\n",
      "kim\n",
      "loại\n",
      "và\n",
      "các\n",
      "sản\n",
      "phẩm\n",
      "từ\n",
      "khoáng\n",
      "phi\n",
      "kim\n",
      "loại\n",
      "ngày\n",
      "niêm\n",
      "yết\n",
      "vốn\n",
      "điều\n",
      "lệ\n",
      "đồng\n",
      "giá\n",
      "đã\n",
      "điều\n",
      "chỉnh\n",
      "đầu\n",
      "năm\n",
      "đồng\n",
      "cpgiá\n",
      "tại\n",
      "ngày\n",
      "phiên\n",
      "cuối\n",
      "năm\n",
      "đồng\n",
      "cp\n",
      "tỷ\n",
      "lệ\n",
      "giảm\n",
      "khối\n",
      "lượng\n",
      "giao\n",
      "dịch\n",
      "bình\n",
      "quân\n",
      "tuần\n",
      "cpnhóm\n",
      "ngành\n",
      "khai\n",
      "khoáng\n",
      "ngành\n",
      "khai\n",
      "khoáng\n",
      "khác\n",
      "ngày\n",
      "niêm\n",
      "yết\n",
      "vốn\n",
      "điều\n",
      "lệ\n",
      "đồnggiá\n",
      "đã\n",
      "điều\n",
      "chỉnh\n",
      "đầu\n",
      "năm\n",
      "đồng\n",
      "cpgiá\n",
      "tại\n",
      "ngày\n",
      "phiên\n",
      "cuối\n",
      "năm\n",
      "đồng\n",
      "cptỷ\n",
      "lệ\n",
      "giảm\n",
      "khối\n",
      "lượng\n",
      "giao\n",
      "dịch\n",
      "bình\n",
      "quân\n",
      "tuần\n",
      "cpnhóm\n",
      "ngành\n",
      "xây\n",
      "dựng\n",
      "và\n",
      "bất\n",
      "động\n",
      "sản\n",
      "ngành\n",
      "xây\n",
      "dựng\n",
      "ngày\n",
      "niêm\n",
      "yết\n",
      "vốn\n",
      "điều\n",
      "lệ\n",
      "đồng\n",
      "giá\n",
      "đã\n",
      "điều\n",
      "chỉnh\n",
      "đầu\n",
      "năm\n",
      "đồng\n",
      "cpgiá\n",
      "tại\n",
      "ngày\n",
      "phiên\n",
      "cuối\n",
      "năm\n",
      "đồng\n",
      "cp\n",
      "tỷ\n",
      "lệ\n",
      "giảm\n",
      "khối\n",
      "lượng\n",
      "giao\n",
      "dịch\n",
      "bình\n",
      "quân\n",
      "tuần\n",
      "cpnhóm\n",
      "ngành\n",
      "sản\n",
      "xuất\n",
      "ngành\n",
      "thực\n",
      "phẩm\n",
      "đồ\n",
      "uống\n",
      "thuốc\n",
      "lá\n",
      "ngày\n",
      "niêm\n",
      "yết\n",
      "vốn\n",
      "điều\n",
      "lệ\n",
      "đồng\n",
      "giá\n",
      "đã\n",
      "điều\n",
      "chỉnh\n",
      "đầu\n",
      "năm\n",
      "đồng\n",
      "cpgiá\n",
      "tại\n",
      "ngày\n",
      "phiên\n",
      "cuối\n",
      "năm\n",
      "đồng\n",
      "cp\n",
      "tỷ\n",
      "lệ\n",
      "giảm\n",
      "khối\n",
      "lượng\n",
      "giao\n",
      "dịch\n",
      "bình\n",
      "quân\n",
      "tuần\n",
      "cpnhóm\n",
      "ngành\n",
      "sản\n",
      "xuất\n",
      "ngành\n",
      "hóa\n",
      "chất\n",
      "dược\n",
      "phẩm\n",
      "ngày\n",
      "niêm\n",
      "yết\n",
      "vốn\n",
      "điều\n",
      "lệ\n",
      "đồnggiá\n",
      "đã\n",
      "điều\n",
      "chỉnh\n",
      "đầu\n",
      "năm\n",
      "đồng\n",
      "cpgiá\n",
      "tại\n",
      "ngày\n",
      "phiên\n",
      "cuối\n",
      "năm\n",
      "đồng\n",
      "cp\n",
      "tỷ\n",
      "lệ\n",
      "giảm\n",
      "khối\n",
      "lượng\n",
      "giao\n",
      "dịch\n",
      "bình\n",
      "quân\n",
      "tuần\n",
      "cpnhóm\n",
      "ngành\n",
      "sản\n",
      "xuất\n",
      "ngành\n",
      "kim\n",
      "loại\n",
      "và\n",
      "các\n",
      "sản\n",
      "phẩm\n",
      "từ\n",
      "khoáng\n",
      "phi\n",
      "kim\n",
      "loại\n",
      "ngày\n",
      "niêm\n",
      "yết\n",
      "vốn\n",
      "điều\n",
      "lệ\n",
      "đồnggiá\n",
      "đã\n",
      "điều\n",
      "chỉnh\n",
      "đầu\n",
      "năm\n",
      "đồng\n",
      "cpgiá\n",
      "tại\n",
      "ngày\n",
      "phiên\n",
      "cuối\n",
      "năm\n",
      "đồng\n",
      "cp\n",
      "tỷ\n",
      "lệ\n",
      "giảm\n",
      "khối\n",
      "lượng\n",
      "giao\n",
      "dịch\n",
      "bình\n",
      "quân\n",
      "tuần\n",
      "cpnhóm\n",
      "ngành\n",
      "sản\n",
      "xuất\n",
      "ngành\n",
      "hóa\n",
      "chất\n",
      "dược\n",
      "phẩm\n",
      "ngày\n",
      "niêm\n",
      "yết\n",
      "vốn\n",
      "điều\n",
      "lệ\n",
      "đồng\n",
      "giá\n",
      "đã\n",
      "điều\n",
      "chỉnh\n",
      "đầu\n",
      "năm\n",
      "đồng\n",
      "cpgiá\n",
      "tại\n",
      "ngày\n",
      "phiên\n",
      "cuối\n",
      "năm\n",
      "đồng\n",
      "cp\n",
      "tỷ\n",
      "lệ\n",
      "giảm\n",
      "khối\n",
      "lượng\n",
      "giao\n",
      "dịch\n",
      "bình\n",
      "quân\n",
      "tuần\n",
      "cpnhóm\n",
      "ngành\n",
      "thương\n",
      "mại\n",
      "ngành\n",
      "bán\n",
      "buôn\n",
      "ngày\n",
      "niêm\n",
      "yết\n",
      "vốn\n",
      "điều\n",
      "lệ\n",
      "đồnggiá\n",
      "đã\n",
      "điều\n",
      "chỉnh\n",
      "đầu\n",
      "năm\n",
      "nbsp\n",
      "đồng\n",
      "cpgiá\n",
      "tại\n",
      "ngày\n",
      "phiên\n",
      "cuối\n",
      "năm\n",
      "đồng\n",
      "cp\n",
      "tỷ\n",
      "lệ\n",
      "giảm\n",
      "khối\n",
      "lượng\n",
      "giao\n",
      "dịch\n",
      "bình\n",
      "quân\n",
      "tuần\n",
      "cp\n",
      "nbsp\n",
      "nhóm\n",
      "ngành\n",
      "xây\n",
      "dựng\n",
      "và\n",
      "bất\n",
      "động\n",
      "sản\n",
      "ngành\n",
      "xây\n",
      "dựng\n",
      "ngày\n",
      "niêm\n",
      "yết\n",
      "vốn\n",
      "điều\n",
      "lệ\n",
      "đồng\n",
      "giá\n",
      "đã\n",
      "điều\n",
      "chỉnh\n",
      "đầu\n",
      "năm\n",
      "nbsp\n",
      "đồng\n",
      "cpgiá\n",
      "tại\n",
      "ngày\n",
      "phiên\n",
      "cuối\n",
      "năm\n",
      "đồng\n",
      "cp\n",
      "tỷ\n",
      "lệ\n",
      "giảm\n",
      "khối\n",
      "lượng\n",
      "giao\n",
      "dịch\n",
      "bình\n",
      "quân\n",
      "tuần\n",
      "cpnhóm\n",
      "ngành\n",
      "vận\n",
      "tải\n",
      "và\n",
      "kho\n",
      "bãi\n",
      "ngành\n",
      "vận\n",
      "chuyển\n",
      "khách\n",
      "đường\n",
      "bộ\n",
      "hệ\n",
      "thống\n",
      "trạm\n",
      "dừng\n",
      "ngày\n",
      "niêm\n",
      "yết\n",
      "vốn\n",
      "điều\n",
      "lệ\n",
      "đồnggiá\n",
      "đã\n",
      "điều\n",
      "chỉnh\n",
      "đầu\n",
      "năm\n",
      "đồng\n",
      "cpgiá\n",
      "tại\n",
      "ngày\n",
      "phiên\n",
      "cuối\n",
      "năm\n",
      "đồng\n",
      "cptỷ\n",
      "lệ\n",
      "giảm\n",
      "khối\n",
      "lượng\n",
      "giao\n",
      "dịch\n",
      "bình\n",
      "quân\n",
      "tuần\n",
      "cpnhóm\n",
      "ngành\n",
      "sản\n",
      "xuất\n",
      "ngành\n",
      "kim\n",
      "loại\n",
      "và\n",
      "các\n",
      "sản\n",
      "phẩm\n",
      "từ\n",
      "khoáng\n",
      "phi\n",
      "kim\n",
      "loại\n",
      "ngày\n",
      "niêm\n",
      "yết\n",
      "vốn\n",
      "điều\n",
      "lệ\n",
      "đồng\n",
      "giá\n",
      "đã\n",
      "điều\n",
      "chỉnh\n",
      "đầu\n",
      "năm\n",
      "đồng\n",
      "cpgiá\n",
      "tại\n",
      "ngày\n",
      "phiên\n",
      "cuối\n",
      "năm\n",
      "đồng\n",
      "cp\n",
      "tỷ\n",
      "lệ\n",
      "giảm\n",
      "khối\n",
      "lượng\n",
      "giao\n",
      "dịch\n",
      "bình\n",
      "quân\n",
      "tuần\n",
      "cpnhóm\n",
      "ngành\n",
      "khai\n",
      "khoáng\n",
      "ngành\n",
      "khai\n",
      "khoáng\n",
      "khác\n",
      "ngày\n",
      "niêm\n",
      "yết\n",
      "vốn\n",
      "điều\n",
      "lệ\n",
      "đồnggiá\n",
      "đã\n",
      "điều\n",
      "chỉnh\n",
      "đầu\n",
      "năm\n",
      "đồng\n",
      "cpgiá\n",
      "tại\n",
      "ngày\n",
      "phiên\n",
      "cuối\n",
      "năm\n",
      "đồng\n",
      "cptỷ\n",
      "lệ\n",
      "giảm\n",
      "khối\n",
      "lượng\n",
      "giao\n",
      "dịch\n",
      "bình\n",
      "quân\n",
      "tuần\n",
      "cpnhóm\n",
      "ngành\n",
      "xây\n",
      "dựng\n",
      "và\n",
      "bất\n",
      "động\n",
      "sản\n",
      "ngành\n",
      "xây\n",
      "dựng\n",
      "ngày\n",
      "niêm\n",
      "yết\n",
      "vốn\n",
      "điều\n",
      "lệ\n",
      "đồng\n",
      "giá\n",
      "đã\n",
      "điều\n",
      "chỉnh\n",
      "đầu\n",
      "năm\n",
      "đồng\n",
      "cpgiá\n",
      "tại\n",
      "ngày\n",
      "phiên\n",
      "cuối\n",
      "năm\n",
      "đồng\n",
      "cp\n",
      "tỷ\n",
      "lệ\n",
      "giảm\n",
      "khối\n",
      "lượng\n",
      "giao\n",
      "dịch\n",
      "bình\n",
      "quân\n",
      "tuần\n",
      "cpnhóm\n",
      "ngành\n",
      "sản\n",
      "xuất\n",
      "ngành\n",
      "thực\n",
      "phẩm\n",
      "đồ\n",
      "uống\n",
      "thuốc\n",
      "lá\n",
      "ngày\n",
      "niêm\n",
      "yết\n",
      "vốn\n",
      "điều\n",
      "lệ\n",
      "đồng\n",
      "giá\n",
      "đã\n",
      "điều\n",
      "chỉnh\n",
      "đầu\n",
      "năm\n",
      "đồng\n",
      "cpgiá\n",
      "tại\n",
      "ngày\n",
      "phiên\n",
      "cuối\n",
      "năm\n",
      "đồng\n",
      "cp\n",
      "tỷ\n",
      "lệ\n",
      "giảm\n",
      "khối\n",
      "lượng\n",
      "giao\n",
      "dịch\n",
      "bình\n",
      "quân\n",
      "tuần\n",
      "cpnhóm\n",
      "ngành\n",
      "sản\n",
      "xuất\n",
      "ngành\n",
      "hóa\n",
      "chất\n",
      "dược\n",
      "phẩm\n",
      "ngày\n",
      "niêm\n",
      "yết\n",
      "vốn\n",
      "điều\n",
      "lệ\n",
      "đồnggiá\n",
      "đã\n",
      "điều\n",
      "chỉnh\n",
      "đầu\n",
      "năm\n",
      "đồng\n",
      "cpgiá\n",
      "tại\n",
      "ngày\n",
      "phiên\n",
      "cuối\n",
      "năm\n",
      "đồng\n",
      "cp\n",
      "tỷ\n",
      "lệ\n",
      "giảm\n",
      "khối\n",
      "lượng\n",
      "giao\n",
      "dịch\n",
      "bình\n",
      "quân\n",
      "tuần\n",
      "cpnhóm\n",
      "ngành\n",
      "sản\n",
      "xuất\n",
      "ngành\n",
      "kim\n",
      "loại\n",
      "và\n",
      "các\n",
      "sản\n",
      "phẩm\n",
      "từ\n",
      "khoáng\n",
      "phi\n",
      "kim\n",
      "loại\n",
      "ngày\n",
      "niêm\n",
      "yết\n",
      "vốn\n",
      "điều\n",
      "lệ\n",
      "đồnggiá\n",
      "đã\n",
      "điều\n",
      "chỉnh\n",
      "đầu\n",
      "năm\n",
      "đồng\n",
      "cpgiá\n",
      "tại\n",
      "ngày\n",
      "phiên\n",
      "cuối\n",
      "năm\n",
      "đồng\n",
      "cp\n",
      "tỷ\n",
      "lệ\n",
      "giảm\n",
      "khối\n",
      "lượng\n",
      "giao\n",
      "dịch\n",
      "bình\n",
      "quân\n",
      "tuần\n",
      "cpnhóm\n",
      "ngành\n",
      "sản\n",
      "xuất\n",
      "ngành\n",
      "hóa\n",
      "chất\n",
      "dược\n",
      "phẩm\n",
      "ngày\n",
      "niêm\n",
      "yết\n",
      "vốn\n",
      "điều\n",
      "lệ\n",
      "đồng\n",
      "giá\n",
      "đã\n",
      "điều\n",
      "chỉnh\n",
      "đầu\n",
      "năm\n",
      "đồng\n",
      "cpgiá\n",
      "tại\n",
      "ngày\n",
      "phiên\n",
      "cuối\n",
      "năm\n",
      "đồng\n",
      "cp\n",
      "tỷ\n",
      "lệ\n",
      "giảm\n",
      "khối\n",
      "lượng\n",
      "giao\n",
      "dịch\n",
      "bình\n",
      "quân\n",
      "tuần\n",
      "cpnhóm\n",
      "ngành\n",
      "thương\n",
      "mại\n",
      "ngành\n",
      "bán\n",
      "buôn\n",
      "ngày\n",
      "niêm\n",
      "yết\n",
      "vốn\n",
      "điều\n",
      "lệ\n",
      "đồnggiá\n",
      "đã\n",
      "điều\n",
      "chỉnh\n",
      "đầu\n",
      "năm\n",
      "nbsp\n",
      "đồng\n",
      "cpgiá\n",
      "tại\n",
      "ngày\n",
      "phiên\n",
      "cuối\n",
      "năm\n",
      "đồng\n",
      "cp\n",
      "tỷ\n",
      "lệ\n",
      "giảm\n",
      "khối\n",
      "lượng\n",
      "giao\n",
      "dịch\n",
      "bình\n",
      "quân\n",
      "tuần\n",
      "cp\n",
      "nbsp\n"
     ]
    }
   ],
   "source": [
    "#convert word strings to integer sequence lists\n",
    "print(X_train[0])\n",
    "print(imdbTokenizer.texts_to_sequences(X_train[:1]))\n",
    "for value in imdbTokenizer.texts_to_sequences(X_train[:1])[0]:\n",
    "    print(intToWord[value])\n",
    "    \n",
    "X_train = imdbTokenizer.texts_to_sequences(X_train)\n",
    "X_test = imdbTokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1092 train sequences\n",
      "463 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (1092L, 200L)\n",
      "X_test shape: (463L, 200L)\n"
     ]
    }
   ],
   "source": [
    "# Censor the data by having a max review length (in number of words)\n",
    "\n",
    "#use this function to load data from keras pickle instead of munging as shown above\n",
    "#(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features,\n",
    "#                                                      test_split=0.2)\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_len)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [ 388  393   55   69  171    4   13   18   69  332   15    5    4 1829   35\n",
      "  114  126  236    5    4  274   10  171   25  285  119   74  112  208  445\n",
      "  289 2000  155   32   76  155  237  453  904  238  114  388  393   55   69\n",
      "  171 3091   18   69  332   15    5    4 1829   35  114  126  236    5    4\n",
      "  274   10  171   25  285  119   74  112  208  445  289 2000  155   32   76\n",
      "  155  641  504    1    7   32  238   26  920  916  641  504  114  388  393\n",
      "   55   69  171 3091   18   69  332   15    5    4 1829   35  114  126  236\n",
      "    5    4  274   10  171   25  285  119   74  112  208  445  289 2000  155\n",
      "   32   76  155  237  453  904  238  114  388  393   55   69  171    4   13\n",
      "   18   69  332   15    5    4 1829   35  114  126  236    5    4  274   10\n",
      "  171   25  285  119   74  112  208  445  289 2000  155  202  331  155   88\n",
      " 1252  114  388  393   55   69  171 3091   18   69  332   15    5   80    4\n",
      " 1829   35  114  126  236    5    4  274   10  171   25  285  119   74  112\n",
      "  208  445  289  274   80]\n",
      "y: 1\n"
     ]
    }
   ],
   "source": [
    "#example of a sentence sequence, note that lower integers are words that occur more commonly\n",
    "print(\"x:\", X_train[0]) #per observation vector of 20000 words\n",
    "print(\"y:\", y_train[0]) #positive or negative review encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y distribution: (array([0, 1]), array([238, 854], dtype=int64))\n",
      "max x word: 6848 ; min x word 0\n",
      "y distribution test: (array([0, 1]), array([ 88, 375], dtype=int64))\n",
      "max x word test: 6803 ; min x word 0\n"
     ]
    }
   ],
   "source": [
    "# double check that word sequences behave/final dimensions are as expected\n",
    "print(\"y distribution:\", np.unique(y_train, return_counts=True))\n",
    "print(\"max x word:\", np.max(X_train), \"; min x word\", np.min(X_train))\n",
    "print(\"y distribution test:\", np.unique(y_test, return_counts=True))\n",
    "print(\"max x word test:\", np.max(X_test), \"; min x word\", np.min(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most and least popular words: \n",
      "(array([   0,    1,    2, ..., 6843, 6846, 6848]), array([6689, 2719, 2475, ...,    1,    1,    1], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(\"most and least popular words: \")\n",
    "print(np.unique(X_train, return_counts=True))\n",
    "# as expected zero is the highly used word for words not in index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set model hyper parameters\n",
    "epochs = 5\n",
    "embedding_neurons = 128\n",
    "lstm_neurons = 64\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's import pre-trained word vectors from google and use them to initialize our embedding to see if this improves the neural net's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:840: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "#get pre trained word2vec from google:\n",
    "#https://doc-0k-4g-docs.googleusercontent.com/docs/securesc/gnqvgap6hjncpd3b10i2tv865io48jas/hmjtdgee48c14e1parufukrpkb8urra5/1463018400000/06848720943842814915/09676831593570546402/0B7XkCwpI5KDYNlNUTTlSS21pQmM?e=download&nonce=4l49745nmtine&user=09676831593570546402&hash=i2qe9mshan4mesl112ct9bu1tj9kr1hq\n",
    "\n",
    "googlew2v = Word2Vec.load_word2vec_format('C:/1_Research/Create_data/aclImdb/word2vector/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.26202468  0.15868397  0.27812652 ...,  0.10937801  0.75767728\n",
      "   0.4428527 ]\n",
      " [ 0.96970407  0.12253514  0.35782362 ...,  0.97491444  0.6667405\n",
      "   0.40817497]\n",
      " [-0.20117188  0.140625    0.00427246 ...,  0.02307129 -0.06298828\n",
      "   0.32226562]\n",
      " ..., \n",
      " [ 0.74221873  0.22051525  0.84255914 ...,  0.13028034  0.15021938\n",
      "   0.21722988]\n",
      " [ 0.77492949  0.61239571  0.28688942 ...,  0.14056612  0.58534851\n",
      "   0.62429266]\n",
      " [ 0.3628167   0.45290652  0.74855452 ...,  0.33012347  0.7255602\n",
      "   0.0751601 ]]\n",
      "(10000L, 300L)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\gensim\\models\\word2vec.py:1578: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  return self.syn0[self.vocab[words].index]\n"
     ]
    }
   ],
   "source": [
    "# get word vectors for words in my index\n",
    "googleVecs = []\n",
    "for value in range(max_features):\n",
    "    try:\n",
    "        googleVecs.append(googlew2v[intToWord[value]])\n",
    "    except:\n",
    "        googleVecs.append(np.random.uniform(size=300))\n",
    "\n",
    "googleVecs = np.array(googleVecs)\n",
    "\n",
    "print(googleVecs)\n",
    "print(googleVecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 200)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 200, 300)      3000000     input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNormal(None, 200, 300)      600         embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "gru_1 (GRU)                      (None, 64)            70080       batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "gru_2 (GRU)                      (None, 64)            70080       batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 128)           0           gru_1[0][0]                      \n",
      "                                                                   gru_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 128)           0           merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             129         dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 3140889\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Bi-directional google\n",
    "\n",
    "# this example tests if using pretrained embeddings will improve performance \n",
    "# relative to starting with random embeddings\n",
    "\n",
    "# this is the placeholder tensor for the input sequences\n",
    "sequence = Input(shape=(max_len,), dtype='int32')\n",
    "# this embedding layer will transform the sequences of integers\n",
    "# into vectors of size embedding\n",
    "# embedding layer converts dense int input to one-hot in real time to save memory\n",
    "embedded = Embedding(max_features, 300, input_length=max_len, weights=[googleVecs])(sequence)\n",
    "# normalize embeddings by input/word in sentence\n",
    "bnorm = BatchNormalization()(embedded)\n",
    "\n",
    "# apply forwards LSTM layer size lstm_neurons\n",
    "forwards = GRU(lstm_neurons, dropout_W=0.4, dropout_U=0.4)(bnorm)\n",
    "# apply backwards LSTM\n",
    "backwards = GRU(lstm_neurons, dropout_W=0.4, dropout_U=0.4, go_backwards=True)(bnorm)\n",
    "\n",
    "# concatenate the outputs of the 2 LSTMs\n",
    "merged = merge([forwards, backwards], mode='concat', concat_axis=-1)\n",
    "after_dp = Dropout(0.5)(merged)\n",
    "output = Dense(1, activation='sigmoid')(after_dp)\n",
    "\n",
    "model_bidir_google = Model(input=sequence, output=output)\n",
    "# review model structure\n",
    "print(model_bidir_google.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 1092 samples, validate on 463 samples\n",
      "Epoch 1/5\n",
      "28s - loss: 0.6634 - acc: 0.6786 - val_loss: 0.5488 - val_acc: 0.8099\n",
      "Epoch 2/5\n",
      "28s - loss: 0.5771 - acc: 0.7454 - val_loss: 0.5299 - val_acc: 0.8121\n",
      "Epoch 3/5\n",
      "30s - loss: 0.5393 - acc: 0.7701 - val_loss: 0.5282 - val_acc: 0.8099\n",
      "Epoch 4/5\n",
      "29s - loss: 0.5270 - acc: 0.7683 - val_loss: 0.5327 - val_acc: 0.8035\n",
      "Epoch 5/5\n",
      "29s - loss: 0.5035 - acc: 0.7729 - val_loss: 0.5403 - val_acc: 0.8035\n",
      "avg sec per epoch: 33.7541999817\n"
     ]
    }
   ],
   "source": [
    "# Bi-directional google\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "model_bidir_google.compile('rmsprop', 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "history_bidir_google = model_bidir_google.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    nb_epoch=epochs,\n",
    "                    validation_data=[X_test, y_test], \n",
    "                    verbose=2)\n",
    "\n",
    "end_time = time.time()\n",
    "average_time_per_epoch = (end_time - start_time) / epochs\n",
    "print(\"avg sec per epoch:\", average_time_per_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
