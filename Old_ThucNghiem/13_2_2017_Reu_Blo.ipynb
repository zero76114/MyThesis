{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Input, merge, BatchNormalization,GRU\n",
    "from keras.datasets import imdb\n",
    "\n",
    "import os\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "path = 'C:/1_Research/Create_data/aclImdb/train/pos/'\n",
    "X_train.extend([open(path + f).read() for f in os.listdir(path) if f.endswith('.txt')])\n",
    "y_train.extend([1 for _ in range(135526)])\n",
    "\n",
    "path = 'C:/1_Research/Create_data/aclImdb/train/neg/'\n",
    "X_train.extend([open(path + f).read() for f in os.listdir(path) if f.endswith('.txt')])\n",
    "y_train.extend([0 for _ in range(100972)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "path = 'C:/1_Research/Create_data/aclImdb/test/pos/'\n",
    "X_test.extend([open(path + f).read() for f in os.listdir(path) if f.endswith('.txt')])\n",
    "y_test.extend([1 for _ in range(135526)])\n",
    "\n",
    "path = 'C:/1_Research/Create_data/aclImdb/test/neg/'\n",
    "X_test.extend([open(path + f).read() for f in os.listdir(path) if f.endswith('.txt')])\n",
    "y_test.extend([0 for _ in range(100972)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: \n",
      "232229\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of words: \")\n",
    "print(len(np.unique(np.hstack(X_train ))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length: \n",
      "Mean 1169.90 words (884.047034)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb0176d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "# Summarize review length\n",
    "print(\"Review length: \")\n",
    "result = map(len, X_train)\n",
    "print(\"Mean %.2f words (%f)\" % (np.mean(result), np.std(result)))\n",
    "# plot review length\n",
    "pyplot.boxplot(result)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "max_features =5000\n",
    "max_len = 100  # cut texts after this number of words (among top max_features most common words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#tokenize works to list of integers where each integer is a key to a word\n",
    "imdbTokenizer = Tokenizer(nb_words=max_features)\n",
    "\n",
    "imdbTokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create int to word dictionary\n",
    "intToWord = {}\n",
    "for word, value in imdbTokenizer.word_index.items():\n",
    "    intToWord[value] = word\n",
    "\n",
    "#add a symbol for null placeholder\n",
    "intToWord[0] = \"!!!NA!!!\"\n",
    "    \n",
    "#print(intToWord[1])\n",
    "#print(intToWord[2])\n",
    "#print(intToWord[32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert word strings to integer sequence lists\n",
    "#print(X_train[0])\n",
    "#print(imdbTokenizer.texts_to_sequences(X_train[:1]))\n",
    "#for value in imdbTokenizer.texts_to_sequences(X_train[:1])[0]:\n",
    "    #print(intToWord[value])\n",
    "    \n",
    "X_train = imdbTokenizer.texts_to_sequences(X_train)\n",
    "X_test = imdbTokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236498 train sequences\n",
      "236498 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (236498L, 100L)\n",
      "X_test shape: (236498L, 100L)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Censor the data by having a max review length (in number of words)\n",
    "\n",
    "#use this function to load data from keras pickle instead of munging as shown above\n",
    "#(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features,\n",
    "#                                                      test_split=0.2)\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_len)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "embedding_neurons = 64\n",
    "lstm_neurons = 128\n",
    "batch_size =32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 100, 64)       320000      input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 100, 64)       256         embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "gru_1 (GRU)                      (None, 128)           74112       batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 128)           0           gru_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             129         dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 394,497\n",
      "Trainable params: 394,369\n",
      "Non-trainable params: 128\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Forward Pass LSTM Network\n",
    "\n",
    "# this is the placeholder tensor for the input sequences\n",
    "sequence = Input(shape=(max_len,), dtype='int32')\n",
    "# this embedding layer will transform the sequences of integers\n",
    "# into vectors of size embedding\n",
    "# embedding layer converts dense int input to one-hot in real time to save memory\n",
    "embedded = Embedding(max_features, embedding_neurons, input_length=max_len)(sequence)\n",
    "# normalize embeddings by input/word in sentence\n",
    "bnorm = BatchNormalization()(embedded)\n",
    "\n",
    "# apply forwards LSTM layer size lstm_neurons\n",
    "forwards = GRU(lstm_neurons, dropout_W=0.4, dropout_U=0.4)(bnorm)\n",
    "\n",
    "# dropout \n",
    "after_dp = Dropout(0.5)(forwards)\n",
    "output = Dense(1, activation='sigmoid')(after_dp)\n",
    "\n",
    "model_fdir_atom = Model(input=sequence, output=output)\n",
    "# review model structure\n",
    "print(model_fdir_atom.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 236498 samples, validate on 236498 samples\n",
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "# Forward pass LSTM network\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model_fdir_atom.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "print('Train...')\n",
    "start_time = time.time()\n",
    "\n",
    "history_fdir_atom = model_fdir_atom.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    nb_epoch=epochs,\n",
    "                    validation_data=[X_test, y_test], \n",
    "                    verbose=2)\n",
    "\n",
    "end_time = time.time()\n",
    "average_time_per_epoch = (end_time - start_time) / epochs\n",
    "print(\"avg sec per epoch:\", average_time_per_epoch)\n",
    "\n",
    "scores = model_fdir_atom.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Bi-directional Atom\n",
    "\n",
    "# based on keras tutorial: https://github.com/fchollet/keras/blob/master/examples/imdb_bidirectional_lstm.py\n",
    "\n",
    "# this is the placeholder tensor for the input sequences\n",
    "sequence = Input(shape=(max_len,), dtype='int32')\n",
    "# this embedding layer will transform the sequences of integers\n",
    "# into vectors of size embedding\n",
    "# embedding layer converts dense int input to one-hot in real time to save memory\n",
    "embedded = Embedding(max_features, embedding_neurons, input_length=max_len)(sequence)\n",
    "# normalize embeddings by input/word in sentence\n",
    "bnorm = BatchNormalization()(embedded)\n",
    "\n",
    "# apply forwards LSTM layer size lstm_neurons\n",
    "forwards = GRU(lstm_neurons, dropout_W=0.4, dropout_U=0.4)(bnorm)\n",
    "# apply backwards LSTM\n",
    "backwards = GRU(lstm_neurons, dropout_W=0.4, dropout_U=0.4, go_backwards=True)(bnorm)\n",
    "\n",
    "# concatenate the outputs of the 2 LSTMs\n",
    "merged = merge([forwards, backwards], mode='concat', concat_axis=-1)\n",
    "after_dp = Dropout(0.5)(merged)\n",
    "output = Dense(1, activation='sigmoid')(after_dp)\n",
    "\n",
    "model_bidir_atom = Model(input=sequence, output=output)\n",
    "# review model structure\n",
    "print(model_bidir_atom.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_bidir_atom.compile('rmsprop', 'binary_crossentropy', metrics=['accuracy','precision', 'recall', 'fmeasure'])\n",
    "\n",
    "print('Train...')\n",
    "start_time = time.time()\n",
    "\n",
    "history_bidir_atom = model_bidir_atom.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    nb_epoch=epochs,\n",
    "                    validation_data=[X_test, y_test], \n",
    "                    verbose=2)\n",
    "\n",
    "end_time = time.time()\n",
    "average_time_per_epoch = (end_time - start_time) / epochs\n",
    "print(\"avg sec per epoch:\", average_time_per_epoch)\n",
    "scores = model_fdir_atom.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
