{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "##Khai báo các thư viện\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Input, merge, BatchNormalization,GRU\n",
    "from keras.datasets import imdb\n",
    "\n",
    "import os\n",
    "from keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Gán nhãn cho dữ liệu train\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "path = 'C:/VS_8D/out/train/pos/'\n",
    "X_train.extend([open(path + f).read() for f in os.listdir(path) if f.endswith('.txt')])\n",
    "\n",
    "y_train.extend([1 for _ in range(735)])\n",
    "\n",
    "path = 'C:/VS_8D/out/train/neg/'\n",
    "X_train.extend([open(path + f).read() for f in os.listdir(path) if f.endswith('.txt')])\n",
    "\n",
    "y_train.extend([0 for _ in range(333)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Gán nhãn cho dữ liệu test\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "path = 'C:/VS_8D/out/test/pos/'\n",
    "X_test.extend([open(path + f).read() for f in os.listdir(path) if f.endswith('.txt')])\n",
    "y_test.extend([1 for _ in range(338)])\n",
    "\n",
    "path = 'C:/VS_8D/out/test/neg/'\n",
    "X_test.extend([open(path + f).read() for f in os.listdir(path) if f.endswith('.txt')])\n",
    "y_test.extend([0 for _ in range(119)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Xử lý remove stop words cho dữ liệu train\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "X_train_rm= []\n",
    "stop_words=set(stopwords.words(\"vietnamese\"))\n",
    "for x in X_train:\n",
    "    words=word_tokenize(x)\n",
    "    remove_sw= [w for w in words if not unicode(w,\"utf8\") in stop_words]\n",
    "    X_train_rm.append(remove_sw),\n",
    "sentence_train=[] \n",
    "for i in range(len(X_train_rm)):\n",
    "    s = \"\"\n",
    "    for j in range(len(X_train_rm[i])):\n",
    "        s+=X_train_rm[i][j]+\" \"\n",
    "    sentence_train.append(s),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Xử lý remove stop words cho dữ liệu test\n",
    "X_test_rm= []\n",
    "stop_words=set(stopwords.words(\"vietnamese\"))\n",
    "for x in X_test:\n",
    "    words=word_tokenize(x)\n",
    "    remove_sw= [w for w in words if not unicode(w,\"utf8\") in stop_words]\n",
    "\n",
    "    X_test_rm.append(remove_sw),\n",
    "sentence_test=[] \n",
    "for i in range(len(X_test_rm)):\n",
    "    s = \"\"\n",
    "    for j in range(len(X_test_rm[i])):\n",
    "        s+=X_test_rm[i][j]+\" \"\n",
    "    sentence_test.append(s),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: \n",
      "1065\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of words: \")\n",
    "print(len(np.unique(np.hstack(X_train ))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length: \n",
      "Mean 5100.79 words (3807.761114)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1165cd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "# Summarize review length\n",
    "print(\"Review length: \")\n",
    "result = map(len, X_train)\n",
    "print(\"Mean %.2f words (%f)\" % (np.mean(result), np.std(result)))\n",
    "# plot review length\n",
    "pyplot.boxplot(result)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Khai báo tham số đặc trưng và chiều dài câu\n",
    "max_features =900\n",
    "max_len = 200  # cut texts after this number of words (among top max_features most common words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Xứ lý tách từ \n",
    "imdbTokenizer = Tokenizer(nb_words=max_features)\n",
    "\n",
    "imdbTokenizer.fit_on_texts(sentence_train)\n",
    "#for word, value in imdbTokenizer.word_index.items():\n",
    "    #print(word),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "đồng\n",
      "năm\n",
      "án\n"
     ]
    }
   ],
   "source": [
    "#create int to word dictionary\n",
    "intToWord = {}\n",
    "for word, value in imdbTokenizer.word_index.items():\n",
    "    intToWord[value] = word\n",
    "\n",
    "#add a symbol for null placeholder\n",
    "intToWord[0] = \"!!!NA!!!\"\n",
    "    \n",
    "print(intToWord[1])\n",
    "print(intToWord[2])\n",
    "print(intToWord[32])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert word strings to integer sequence lists\n",
    "#print(X_train[0])\n",
    "#print(imdbTokenizer.texts_to_sequences(X_train[:1]))\n",
    "#for value in imdbTokenizer.texts_to_sequences(X_train[:1])[0]:\n",
    "    #print(intToWord[value])\n",
    "    \n",
    "X_train = imdbTokenizer.texts_to_sequences(sentence_train)\n",
    "X_test = imdbTokenizer.texts_to_sequences(sentence_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068 train sequences\n",
      "457 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (1068L, 200L)\n",
      "X_test shape: (457L, 200L)\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_len)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "embedding_neurons = 64\n",
    "lstm_neurons = 128\n",
    "batch_size =32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 200)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 200, 64)       57600       input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 200, 64)       256         embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "gru_1 (GRU)                      (None, 128)           74112       batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "gru_2 (GRU)                      (None, 128)           74112       batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 256)           0           gru_1[0][0]                      \n",
      "                                                                   gru_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 256)           0           merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             257         dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 206,337\n",
      "Trainable params: 206,209\n",
      "Non-trainable params: 128\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Bi-directional Atom\n",
    "\n",
    "# based on keras tutorial: https://github.com/fchollet/keras/blob/master/examples/imdb_bidirectional_lstm.py\n",
    "\n",
    "# this is the placeholder tensor for the input sequences\n",
    "sequence = Input(shape=(max_len,), dtype='int32')\n",
    "# this embedding layer will transform the sequences of integers\n",
    "# into vectors of size embedding\n",
    "# embedding layer converts dense int input to one-hot in real time to save memory\n",
    "embedded = Embedding(max_features, embedding_neurons, input_length=max_len)(sequence)\n",
    "# normalize embeddings by input/word in sentence\n",
    "bnorm = BatchNormalization()(embedded)\n",
    "\n",
    "# apply forwards LSTM layer size lstm_neurons\n",
    "forwards = GRU(lstm_neurons, dropout_W=0.4, dropout_U=0.4)(bnorm)\n",
    "# apply backwards LSTM\n",
    "backwards = GRU(lstm_neurons, dropout_W=0.4, dropout_U=0.4, go_backwards=True)(bnorm)\n",
    "\n",
    "# concatenate the outputs of the 2 LSTMs\n",
    "merged = merge([forwards, backwards], mode='concat', concat_axis=-1)\n",
    "after_dp = Dropout(0.5)(merged)\n",
    "output = Dense(1, activation='sigmoid')(after_dp)\n",
    "\n",
    "model_bidir_atom = Model(input=sequence, output=output)\n",
    "# review model structure\n",
    "print(model_bidir_atom.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 1068 samples, validate on 457 samples\n",
      "Epoch 1/1\n",
      "26s - loss: 0.6752 - acc: 0.6320 - precision: 0.7142 - recall: 0.7790 - fmeasure: 0.7392 - val_loss: 0.5961 - val_acc: 0.7396 - val_precision: 0.7396 - val_recall: 0.7702 - val_fmeasure: 0.7506\n",
      "avg sec per epoch: 49.1490001678\n",
      "Accuracy: 73.96%\n"
     ]
    }
   ],
   "source": [
    "# Bi-directional Atom\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model_bidir_atom.compile('rmsprop', 'binary_crossentropy', metrics=['accuracy','precision', 'recall', 'fmeasure'])\n",
    "\n",
    "print('Train...')\n",
    "start_time = time.time()\n",
    "\n",
    "history_bidir_atom = model_bidir_atom.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    nb_epoch=epochs,\n",
    "                    validation_data=[X_test, y_test], \n",
    "                    verbose=2)\n",
    "\n",
    "end_time = time.time()\n",
    "average_time_per_epoch = (end_time - start_time) / epochs\n",
    "print(\"avg sec per epoch:\", average_time_per_epoch)\n",
    "scores = model_bidir_atom.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
