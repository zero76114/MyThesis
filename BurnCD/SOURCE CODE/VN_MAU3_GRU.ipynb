{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "##Khai báo các thư viện\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Input, merge, BatchNormalization,GRU\n",
    "from keras.datasets import imdb\n",
    "\n",
    "import os\n",
    "from keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Gán nhãn cho dữ liệu train\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "path = 'C:/VS_12D/train/pos/'\n",
    "X_train.extend([open(path + f).read() for f in os.listdir(path) if f.endswith('.txt')])\n",
    "\n",
    "y_train.extend([1 for _ in range(929)])\n",
    "\n",
    "path = 'C:/VS_12D/train/neg/'\n",
    "X_train.extend([open(path + f).read() for f in os.listdir(path) if f.endswith('.txt')])\n",
    "\n",
    "y_train.extend([0 for _ in range(390)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Gán nhãn cho dữ liệu test\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "path = 'C:/VS_12D/test/pos/'\n",
    "X_test.extend([open(path + f).read() for f in os.listdir(path) if f.endswith('.txt')])\n",
    "y_test.extend([1 for _ in range(423)])\n",
    "\n",
    "path = 'C:/VS_12D/test/neg/'\n",
    "X_test.extend([open(path + f).read() for f in os.listdir(path) if f.endswith('.txt')])\n",
    "y_test.extend([0 for _ in range(142)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Xử lý remove stop words cho dữ liệu train\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "X_train_rm= []\n",
    "stop_words=set(stopwords.words(\"vietnamese\"))\n",
    "for x in X_train:\n",
    "    words=word_tokenize(x)\n",
    "    remove_sw= [w for w in words if not unicode(w,\"utf8\") in stop_words]\n",
    "    X_train_rm.append(remove_sw),\n",
    "sentence_train=[] \n",
    "for i in range(len(X_train_rm)):\n",
    "    s = \"\"\n",
    "    for j in range(len(X_train_rm[i])):\n",
    "        s+=X_train_rm[i][j]+\" \"\n",
    "    sentence_train.append(s),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Xử lý remove stop words cho dữ liệu test\n",
    "X_test_rm= []\n",
    "stop_words=set(stopwords.words(\"vietnamese\"))\n",
    "for x in X_test:\n",
    "    words=word_tokenize(x)\n",
    "    remove_sw= [w for w in words if not unicode(w,\"utf8\") in stop_words]\n",
    "\n",
    "    X_test_rm.append(remove_sw),\n",
    "sentence_test=[] \n",
    "for i in range(len(X_test_rm)):\n",
    "    s = \"\"\n",
    "    for j in range(len(X_test_rm[i])):\n",
    "        s+=X_test_rm[i][j]+\" \"\n",
    "    sentence_test.append(s),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: \n",
      "1316\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of words: \")\n",
    "print(len(np.unique(np.hstack(X_train ))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length: \n",
      "Mean 5292.39 words (3755.772228)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112e9c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "# Summarize review length\n",
    "print(\"Review length: \")\n",
    "result = map(len, X_train)\n",
    "print(\"Mean %.2f words (%f)\" % (np.mean(result), np.std(result)))\n",
    "# plot review length\n",
    "pyplot.boxplot(result)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Khai báo tham số đặc trưng và chiều dài câu\n",
    "max_features =900\n",
    "max_len = 200  # cut texts after this number of words (among top max_features most common words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Xứ lý tách từ \n",
    "imdbTokenizer = Tokenizer(nb_words=max_features)\n",
    "\n",
    "imdbTokenizer.fit_on_texts(sentence_train)\n",
    "#for word, value in imdbTokenizer.word_index.items():\n",
    "    #print(word),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "đồng\n",
      "năm\n",
      "một\n"
     ]
    }
   ],
   "source": [
    "#create int to word dictionary\n",
    "intToWord = {}\n",
    "for word, value in imdbTokenizer.word_index.items():\n",
    "    intToWord[value] = word\n",
    "\n",
    "#add a symbol for null placeholder\n",
    "intToWord[0] = \"!!!NA!!!\"\n",
    "    \n",
    "print(intToWord[1])\n",
    "print(intToWord[2])\n",
    "print(intToWord[32])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert word strings to integer sequence lists\n",
    "#print(X_train[0])\n",
    "#print(imdbTokenizer.texts_to_sequences(X_train[:1]))\n",
    "#for value in imdbTokenizer.texts_to_sequences(X_train[:1])[0]:\n",
    "    #print(intToWord[value])\n",
    "    \n",
    "X_train = imdbTokenizer.texts_to_sequences(sentence_train)\n",
    "X_test = imdbTokenizer.texts_to_sequences(sentence_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1319 train sequences\n",
      "565 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (1319L, 200L)\n",
      "X_test shape: (565L, 200L)\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_len)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "embedding_neurons = 64\n",
    "lstm_neurons = 128\n",
    "batch_size =32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 200)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)          (None, 200, 64)       57600       input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 200, 64)       256         embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "gru_4 (GRU)                      (None, 128)           74112       batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 128)           0           gru_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1)             129         dropout_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 132,097\n",
      "Trainable params: 131,969\n",
      "Non-trainable params: 128\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Forward Pass GRU Network\n",
    "\n",
    "# this is the placeholder tensor for the input sequences\n",
    "sequence = Input(shape=(max_len,), dtype='int32')\n",
    "# this embedding layer will transform the sequences of integers\n",
    "# into vectors of size embedding\n",
    "# embedding layer converts dense int input to one-hot in real time to save memory\n",
    "embedded = Embedding(max_features, embedding_neurons, input_length=max_len)(sequence)\n",
    "# normalize embeddings by input/word in sentence\n",
    "bnorm = BatchNormalization()(embedded)\n",
    "\n",
    "# apply forwards GRU layer size lstm_neurons\n",
    "forwards = GRU(lstm_neurons, dropout_W=0.4, dropout_U=0.4)(bnorm)\n",
    "\n",
    "# dropout \n",
    "after_dp = Dropout(0.5)(forwards)\n",
    "output = Dense(1, activation='sigmoid')(after_dp)\n",
    "\n",
    "model_fdir_atom = Model(input=sequence, output=output)\n",
    "# review model structure\n",
    "print(model_fdir_atom.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 1319 samples, validate on 565 samples\n",
      "Epoch 1/3\n",
      "26s - loss: 0.5817 - acc: 0.7074 - precision: 0.7337 - recall: 0.9178 - fmeasure: 0.8125 - val_loss: 0.5764 - val_acc: 0.7487 - val_precision: 0.6702 - val_recall: 0.7929 - val_fmeasure: 0.7566\n",
      "Epoch 2/3\n",
      "26s - loss: 0.5300 - acc: 0.7415 - precision: 0.7647 - recall: 0.9147 - fmeasure: 0.8302 - val_loss: 0.5685 - val_acc: 0.7487 - val_precision: 0.6935 - val_recall: 0.7929 - val_fmeasure: 0.7566\n",
      "Epoch 3/3\n",
      "26s - loss: 0.4871 - acc: 0.7892 - precision: 0.8040 - recall: 0.9286 - fmeasure: 0.8594 - val_loss: 0.5716 - val_acc: 0.7487 - val_precision: 0.7084 - val_recall: 0.7929 - val_fmeasure: 0.7566\n",
      "avg sec per epoch: 32.0926667054\n",
      "Accuracy: 70.84%\n"
     ]
    }
   ],
   "source": [
    "# Bi-directional Atom\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model_bidir_atom.compile('rmsprop', 'binary_crossentropy', metrics=['accuracy','precision', 'recall', 'fmeasure'])\n",
    "\n",
    "print('Train...')\n",
    "start_time = time.time()\n",
    "\n",
    "history_bidir_atom = model_bidir_atom.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    nb_epoch=epochs,\n",
    "                    validation_data=[X_test, y_test], \n",
    "                    verbose=2)\n",
    "\n",
    "end_time = time.time()\n",
    "average_time_per_epoch = (end_time - start_time) / epochs\n",
    "print(\"avg sec per epoch:\", average_time_per_epoch)\n",
    "scores = model_bidir_atom.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
